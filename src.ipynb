{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Source Code for Lab Exercise 3.\n",
    "## Steps\n",
    "1. Preprocess the Data.\n",
    "2. Create a Train and Test Split\n",
    "3. Create a Convolutional Neural Network using Keras.\n",
    "4. Experiment on Various Elements\n",
    "5. Discussion and Analysis of Experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Things to Experiment on\n",
    "1. Other Preprocessing methods for Images.\n",
    "2. Adding Max Pooling.\n",
    "3. Changing number of Filters.\n",
    "4. Changing Kernel Size.\n",
    "5. Changing Learning Rate.\n",
    "6. Changing Optimizers.\n",
    "7. TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Dataset for valid Image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"hair_types\"\n",
    "IMAGE_EXTENSIONS = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(DATA_DIR).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in IMAGE_EXTENSIONS:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "            os.remove(filepath)\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "            os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Images and Creating Train/Test Splits using Keras util methods\n",
    "#### Learn more:\n",
    "```\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Define parameters for preprocessor\n",
    "BATCH_SIZE = 32\n",
    "HEIGHT = 64\n",
    "WIDTH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing images from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a dataset using keras.util\n",
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"hair_types\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    labels='inferred'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(np.argmax(labels[i])))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "##### Since the image data is not that many, we artificially produce sample images by flipping or rotating the present images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "]\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(augmented_images[0]).astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data as tf_data\n",
    "# Configuring dataset for performance\n",
    "# Apply `data_augmentation` to the training images.\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf_data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Adding Max Pooling.\n",
    "# 3. Changing number of Filters.\n",
    "# 4. Changing Kernel Size.\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "        \n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # We specify activation=None so as to return logits\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=(HEIGHT, WIDTH) + (3,), num_classes=3)\n",
    "tf.keras.utils.plot_model(model, to_file='test_logs//model_test.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Changing Learning Rate.\n",
    "# 6. Changing Optimizers.\n",
    "EPOCHS = 50\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"test_logs/checkpoint/save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # optimizer=keras.optimizers.\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
    ")\n",
    "cnn = model.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = keras.preprocessing.image.load_img(\n",
    "#     \"hair_types/Curly_Hair/02dac897d1dec9ba8c057a11d041ada8--layered-natural-hair-natural-black-hairstyles.jpg\", target_size=(HEIGHT, WIDTH)\n",
    "# )\n",
    "# img_array = keras.preprocessing.image.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# print(\n",
    "#     \"This image is %.2f percent curly hair, %.2f percent straight hair, and %.2f percent wavy hair.\"\n",
    "#     % tuple(predictions[0])\n",
    "# )\n",
    "\n",
    "img_path = \"hair_types/Curly_Hair/02dac897d1dec9ba8c057a11d041ada8--layered-natural-hair-natural-black-hairstyles.jpg\"\n",
    "img = keras.preprocessing.image.load_img(img_path, target_size=(HEIGHT, WIDTH))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "# Predict probabilities\n",
    "predictions = model.predict(img_array)[0]  \n",
    "\n",
    "# Scale predictions to percentages\n",
    "total_percentage = sum(predictions)\n",
    "scaled_predictions = [p * 100 / total_percentage for p in predictions]\n",
    "\n",
    "class_names = [\"Curly Hair\", \"Straight Hair\", \"Wavy Hair\"]  \n",
    "percentage_str = \", \".join([\"%.2f percent %s\" % (p, class_names[i]) for i, p in enumerate(scaled_predictions)])\n",
    "print(\"This image is \" + percentage_str + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Model with respect to Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cnn.history['accuracy']\n",
    "val_acc = cnn.history['val_accuracy']\n",
    "\n",
    "loss = cnn.history['loss']\n",
    "val_loss = cnn.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
